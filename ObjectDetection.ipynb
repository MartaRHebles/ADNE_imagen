{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddcf13a",
   "metadata": {},
   "source": [
    "# YOLO Object Detection\n",
    "\n",
    "- YOLO takes a completely different approach.\n",
    "- Itâ€™s not a traditional classifier that is repurposed to be an object detector.\n",
    "- YOLO actually looks at the image just once (hence its name: You Only Look Once) but in a clever way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a226e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Darknet' from 'darknet' (c:\\Users\\marta\\anaconda3\\Lib\\site-packages\\darknet\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/marta/Desktop/datos no estuct/ADNE_imagen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarknet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Darknet\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Darknet' from 'darknet' (c:\\Users\\marta\\anaconda3\\Lib\\site-packages\\darknet\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/marta/Desktop/datos no estuct/ADNE_imagen')\n",
    "\n",
    "from utils import *\n",
    "from darknet import Darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68327b22",
   "metadata": {},
   "source": [
    "*Setting Up The Neural Network*\n",
    "\n",
    "We will be using the latest version of YOLO, known as YOLOv3. We have already downloaded the `yolov3.cfg` file that contains the network architecture used by YOLOv3 and placed it in the `/cfg/` folder. Similarly, we have placed the `yolov3.weights` file that contains the pre-trained weights in the `/weights/` directory. Finally, the `melanomas.names` file that has the list of the 80 object classes that the weights were trained to detect.\n",
    "\n",
    "In the code below, we start by specifying the location of the files that contain the neural network architecture, the pre-trained weights, and the object classes.  We then use *Darknet* to setup the neural network using the network architecture specified in the `cfg_file`. We then use the`.load_weights()` method to load our set of pre-trained weights into the model. Finally, we use the `load_class_names()` function, from the `utils` module, to load the 80 object classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b15633",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Darknet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m namesfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmelanomas.names\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load the network architecture\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m m \u001b[38;5;241m=\u001b[39m Darknet(cfg_file)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Load the pre-trained weights\u001b[39;00m\n\u001b[0;32m     14\u001b[0m m\u001b[38;5;241m.\u001b[39mload_weights(weight_file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Darknet' is not defined"
     ]
    }
   ],
   "source": [
    "# Set the location and name of the cfg file\n",
    "cfg_file = './cfg/yolov3.cfg'\n",
    "\n",
    "# Set the location and name of the pre-trained weights file\n",
    "weight_file = './weights/yolov3.weights'\n",
    "\n",
    "# Set the location and name of the COCO object classes file\n",
    "namesfile = 'melanomas.names'\n",
    "\n",
    "# Load the network architecture\n",
    "m = Darknet(cfg_file)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "m.load_weights(weight_file)\n",
    "\n",
    "# Load the COCO object classes\n",
    "class_names = load_class_names(namesfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde5d04",
   "metadata": {},
   "source": [
    "*Taking a Look at The Neural Network*\n",
    "\n",
    "Now that the neural network has been setup, we can see what it looks like. We can print the network using the `.print_network()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the neural network used in YOLOv3\n",
    "m.print_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e59a26",
   "metadata": {},
   "source": [
    "As we can see, the neural network used by YOLOv3 consists mainly of convolutional layers, with some shortcut connections and upsample layers. For a full description of this network please refer to the <a href=\"https://pjreddie.com/media/files/papers/YOLOv3.pdf\">YOLOv3 Paper</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2106e17",
   "metadata": {},
   "source": [
    "*Loading and Resizing Our Images*\n",
    "\n",
    "In the code below, we load our images using OpenCV's `cv2.imread()` function. Since, this function loads images as BGR we will convert our images to RGB so we can display them with the correct colors.\n",
    "\n",
    "As we can see in the previous cell, the input size of the first layer of the network is 416 x 416 x 3. Since images have different sizes, we have to resize our images to be compatible with the input size of the first layer in the network. In the code below, we resize our images using OpenCV's `cv2.resize()` function. We then plot the original and resized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [24.0, 14.0]\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('./images/dog.jpg')\n",
    "\n",
    "# Convert the image to RGB\n",
    "original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# We resize the image to the input width and height of the first layer of the network.\n",
    "resized_image = cv2.resize(original_image, (m.width, m.height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db10a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the images\n",
    "#plt.subplot(121)\n",
    "#plt.title('Original Image')\n",
    "#plt.imshow(original_image)\n",
    "plt.subplot(122)\n",
    "plt.title('Resized Image')\n",
    "plt.imshow(resized_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be1224",
   "metadata": {},
   "source": [
    "*Setting the Non-Maximal Suppression Threshold and the intersection Over Union Threshold*\n",
    "\n",
    "YOLO uses **Non-Maximal Suppression (NMS)** to only keep the best bounding box. The first step in NMS is to remove all the predicted bounding boxes that have a detection probability that is less than a given NMS threshold.  In the code below, we set this NMS threshold to `0.6`. This means that all predicted bounding boxes that have a detection probability less than 0.6 will be removed.\n",
    "\n",
    "After removing all the predicted bounding boxes that have a low detection probability, the second step in NMS, is to select the bounding boxes with the highest detection probability and eliminate all the bounding boxes whose **Intersection Over Union (IOU)** value does not match  a given IOU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9382eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the NMS threshold\n",
    "nms_thresh = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the IOU threshold\n",
    "iou_thresh = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05830f57",
   "metadata": {},
   "source": [
    "*Object Detection*\n",
    "\n",
    "Once the image has been loaded and resized, and you have chosen your parameters for `nms_thresh` and `iou_thresh`, we can use the YOLO algorithm to detect objects in the image. We detect the objects using the `detect_objects(m, resized_image, iou_thresh, nms_thresh)`function from the `utils` module. This function takes in the model `m` returned by *Darknet*, the resized image, and the NMS and IOU thresholds, and returns the bounding boxes of the objects found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [24.0, 14.0]\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('./images/dog.jpg')\n",
    "\n",
    "# Convert the image to RGB\n",
    "original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# We resize the image to the input width and height of the first layer of the network.\n",
    "resized_image = cv2.resize(original_image, (m.width, m.height))\n",
    "\n",
    "# Set the IOU threshold. Default value is 0.4\n",
    "iou_thresh = 0.4\n",
    "\n",
    "# Set the NMS threshold. Default value is 0.6\n",
    "nms_thresh = 0.6\n",
    "\n",
    "# Detect objects in the image\n",
    "boxes = detect_objects(m, resized_image, iou_thresh, nms_thresh)\n",
    "\n",
    "# Print the objects found and the confidence level\n",
    "print_objects(boxes, class_names)\n",
    "\n",
    "#Plot the image with bounding boxes and corresponding object class labels\n",
    "plot_boxes(original_image, boxes, class_names, plot_labels = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
